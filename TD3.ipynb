{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning and Computer Vision\n",
    "\n",
    "### Training a small network\n",
    "\n",
    "Shani Israelov\n",
    "\n",
    "Jean Monnet University, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to train a small network with dense layers for the classification of\n",
    "handwritten digits. We are using the MNIST dataset, composed of 70,000 images: 60,000 for\n",
    "training and 10,000 for testing. This is a classification problem with 10 categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0/ Run the provided codes (Keras and Pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.4365 - accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.3107 - accuracy: 0.9105\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2975 - accuracy: 0.9151\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2905 - accuracy: 0.9176\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2857 - accuracy: 0.9192\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2803 - accuracy: 0.9217\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2776 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.9229\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2747 - accuracy: 0.9226\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.9237\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.2828 - accuracy: 0.9217\n",
      "Test accuracy: 0.9217000007629395\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist     \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "Sbatch=128\n",
    "Nepochs=10\n",
    "lr=1\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Image Preprocessing\n",
    "X_train = X_train.astype('float32')  \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255                     \n",
    "X_test /= 255\n",
    "\n",
    "# Labels\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Create the Network\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=gradient_descent_v2.SGD(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, Y_train, batch_size=Sbatch, epochs=Nepochs, verbose=1)\n",
    "\n",
    "# Test\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions about the Keras code (if you have time, you can do that again on the Pytorch code, after):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ What is the size of each image ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of each image is:\", X_train[0,:].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Display some labels before and after the function ‘to_categorical’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Label for image \", i, \"is y = \", y_train[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/ What is the aim of the ‘Flatten’ function ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* \n",
    "\n",
    "Flattens the input. Does not affect the batch size. if the input is size (1, 10, 64) after Flatten() it would be 640"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/ How many layers do we have in the current network ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "Only 1, the Dense layer.\n",
    "\n",
    "Sequential() groups a linear stack of layers into a tf.keras.Model,\n",
    "\n",
    "Flatten() flattens the input, \n",
    "\n",
    "Dense() is just your regular densely-connected NN layer,\n",
    "\n",
    "Activation('softmax') returns values in range (0,1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/ How many weights to be learned ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "Dense() is getting as an input the Flatten() result. since the data is of size 28x28, the Flatten result would be 784."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/ What are the loss function, the optimization algorithm and its parameter(s) ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "'\n",
    "model.compile(loss='categorical_crossentropy', optimizer=gradient_descent_v2.SGD(learning_rate=lr), metrics=['accuracy'])\n",
    "'\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "the loss function is used to compute the quantity that the the model should seek to minimize during training. For regression models, the commonly used loss function used is mean squared error function while for classification models predicting the probability, the loss function most commonly used is cross entropy.\n",
    "categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels. The output label is assigned one-hot category encoding value in form of 0s and 1. The output label, if present in integer form, is converted into categorical encoding using keras.utils to_categorical method.\n",
    "\n",
    "\n",
    "optimizer=gradient_descent_v2.SGD(learning_rate=lr)\n",
    "\n",
    "An optimizer is one of the two arguments required for compiling a Keras model.\n",
    "SGD is Stochastic gradient descent optimizer.\n",
    "update rule for parameter w with gradient g when momentum is 0:\n",
    "w = w - learning_rate * g\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/ What does ‘469/469’ mean in the output results ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "training_data_size divided by batch_size.\n",
    "\n",
    "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated.\n",
    "\n",
    "in each epoc, we go through out all the training set, meaning we go over 128 samples 469 times. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/Sbatch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8/ Observe the prediction for the first test image and compare it with the actual label. Display the\n",
    "first test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9/ Display the learned weights of each neuron as an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/ Insert FC layers (no convolution) and observe the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11/ Change the learning rate and observe the impact on the results. Do not touch the batch size or\n",
    "the epoch number yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12/ Apply a 5-fold cross validation to tune the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13/ Provide your best architecture and the number of learned weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14/ Try different batch sizes and explain the influence on accuracy and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ce47280533a050555d7b4f68eeea0130aedc5e28a0a82ffba1c2960ac9c248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
