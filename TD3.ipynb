{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning and Computer Vision\n",
    "\n",
    "### Training a small network\n",
    "\n",
    "Shani Israelov\n",
    "\n",
    "Jean Monnet University, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to train a small network with dense layers for the classification of\n",
    "handwritten digits. We are using the MNIST dataset, composed of 70,000 images: 60,000 for\n",
    "training and 10,000 for testing. This is a classification problem with 10 categories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0/ Run the provided codes (Keras and Pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.4373 - accuracy: 0.8764\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9105\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9156\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9182\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2850 - accuracy: 0.9193\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.9210\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9222\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.2723 - accuracy: 0.9244\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.2718 - accuracy: 0.9240\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.9169\n",
      "Test accuracy: 0.9168999791145325\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist     \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import gradient_descent_v2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "Sbatch=128\n",
    "Nepochs=10\n",
    "lr=1\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Image Preprocessing\n",
    "X_train = X_train.astype('float32')  \n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255                     \n",
    "X_test /= 255\n",
    "\n",
    "# Labels\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# Create the Network\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=gradient_descent_v2.SGD(learning_rate=lr), metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model.fit(X_train, Y_train, batch_size=Sbatch, epochs=Nepochs, verbose=1)\n",
    "\n",
    "# Test\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions about the Keras code (if you have time, you can do that again on the Pytorch code, after):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1/ What is the size of each image ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of each image is: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"The size of each image is:\", X_train[0,:].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2/ Display some labels before and after the function ‘to_categorical’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(6,1)\n",
    "for i in range(5):\n",
    "    plt.imshow(X_train[i,:]/255.)\n",
    "    plt.xlabel(y_train[i])\n",
    "    axs[i].imshow(X_train[i,:]/255.)\n",
    "    axs[i].set_title(str(y_train[i]))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3/ What is the aim of the ‘Flatten’ function ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* \n",
    "\n",
    "Flattens the input. Does not affect the batch size. if the input is size (1, 10, 64) after Flatten() it would be 640"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/ How many layers do we have in the current network ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "Only 1, the Dense layer.\n",
    "\n",
    "Sequential() groups a linear stack of layers into a tf.keras.Model,\n",
    "\n",
    "Flatten() flattens the input, \n",
    "\n",
    "Dense() is just your regular densely-connected NN layer,\n",
    "\n",
    "Activation('softmax') returns values in range (0,1)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5/ How many weights to be learned ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "Dense() is getting as an input the Flatten() result. since the data is of size 28x28, the Flatten result would be 784."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6/ What are the loss function, the optimization algorithm and its parameter(s) ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "'\n",
    "model.compile(loss='categorical_crossentropy', optimizer=gradient_descent_v2.SGD(learning_rate=lr), metrics=['accuracy'])\n",
    "'\n",
    "\n",
    "loss='categorical_crossentropy'\n",
    "\n",
    "the loss function is used to compute the quantity that the the model should seek to minimize during training. For regression models, the commonly used loss function used is mean squared error function while for classification models predicting the probability, the loss function most commonly used is cross entropy.\n",
    "categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels. The output label is assigned one-hot category encoding value in form of 0s and 1. The output label, if present in integer form, is converted into categorical encoding using keras.utils to_categorical method.\n",
    "\n",
    "\n",
    "optimizer=gradient_descent_v2.SGD(learning_rate=lr)\n",
    "\n",
    "An optimizer is one of the two arguments required for compiling a Keras model.\n",
    "SGD is Stochastic gradient descent optimizer.\n",
    "update rule for parameter w with gradient g when momentum is 0:\n",
    "w = w - learning_rate * g\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7/ What does ‘469/469’ mean in the output results ?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*\n",
    "\n",
    "training_data_size divided by batch_size.\n",
    "\n",
    "The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the model’s internal parameters are updated.\n",
    "\n",
    "in each epoc, we go through out all the training set, meaning we go over 128 samples 469 times. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.75"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]/Sbatch\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8/ Observe the prediction for the first test image and compare it with the actual label. Display the\n",
    "first test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_input'), name='flatten_input', description=\"created by layer 'flatten_input'\"), but it was called on an input with incompatible shape (None, 28).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\GitRepos\\deep-learning-class-ujm\\TD3.ipynb Cell 22\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/GitRepos/deep-learning-class-ujm/TD3.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test[\u001b[39m3\u001b[39;49m, :, :])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/GitRepos/deep-learning-class-ujm/TD3.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredictions shape:\u001b[39m\u001b[39m\"\u001b[39m, predictions\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filemzfc1xu_.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Shani\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 277, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 784, but received input with shape (None, 28)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 28), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[3, :, :])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9/ Display the learned weights of each neuron as an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/ Insert FC layers (no convolution) and observe the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11/ Change the learning rate and observe the impact on the results. Do not touch the batch size or\n",
    "the epoch number yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12/ Apply a 5-fold cross validation to tune the learning rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13/ Provide your best architecture and the number of learned weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14/ Try different batch sizes and explain the influence on accuracy and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ce47280533a050555d7b4f68eeea0130aedc5e28a0a82ffba1c2960ac9c248"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
